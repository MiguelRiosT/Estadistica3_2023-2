{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec637cfa-2a4c-4ef3-805c-169bcd8df7c2",
   "metadata": {},
   "source": [
    "# Punto 5 - Final - Miguel Rios Tangarife "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c978fa-2821-4873-8aad-a192b88c88a6",
   "metadata": {},
   "source": [
    "## Cree el modelo en python utilizando las librerías, que palabras son las mas importantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6e29d89-96aa-485c-984c-4ae244ff540d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "889ada23-e0ae-4c4f-8402-e8d6a27514d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Miguel\n",
      "[nltk_data]     Rios\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Miguel\n",
      "[nltk_data]     Rios\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Miguel\n",
      "[nltk_data]     Rios\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36f45bf0-b2b9-4128-8ccb-f4bb908bf631",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = 'latin1'\n",
    "ruta_archivo_csv = 'data/datoss.csv'\n",
    "datosFinal = pd.read_csv(ruta_archivo_csv, encoding=encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05c0781a-8920-4ee4-ac06-20a0e249fecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pasar todos los datos a minúsculas\n",
    "datosFinal['Texto'] = datosFinal['Texto'].str.lower()\n",
    "\n",
    "# Lematización y eliminación de stopwords\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('spanish'))\n",
    "def lemmatize_text(text):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return ' '.join([word for word in lemmatized_words if word not in stop_words])\n",
    "# Aplicar lematización y eliminación de stopwords\n",
    "datosFinal['Texto'] = datosFinal['Texto'].apply(lemmatize_text)\n",
    "\n",
    "# Convertir todo el texto a minúsculas después de la lematización y eliminación de stopwords\n",
    "datosFinalClear = datosFinal.copy()\n",
    "datosFinalClear['Texto'] = datosFinalClear['Texto'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5699ef18-c68d-41ba-8bdb-31cf84623953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Texto</th>\n",
       "      <th>Sentimiento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aprendi regresiones</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mucha tarea</td>\n",
       "      <td>Negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aprendi modelos texto</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tareas largas</td>\n",
       "      <td>Negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aprendi utilizar imágenes</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>profe demora entregar notas</td>\n",
       "      <td>Negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gusto competir mejor modelo</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>examenes largo</td>\n",
       "      <td>Negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>aprendi gradientes</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>aprendi nlp</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>aprendi redes neuronales</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>falto aprender ma spark</td>\n",
       "      <td>Negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>office hour sabados</td>\n",
       "      <td>Negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>aprendi python</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>aprendi pca</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>aprendi cluster</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tareas practicas</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>aprendi q derivadas utiles</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>panda com excel gusto</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>confio grabaciones distraigo parte teorica</td>\n",
       "      <td>Negativo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Texto Sentimiento\n",
       "0                          aprendi regresiones    Positivo\n",
       "1                                  mucha tarea    Negativo\n",
       "2                        aprendi modelos texto    Positivo\n",
       "3                                tareas largas    Negativo\n",
       "4                    aprendi utilizar imágenes    Positivo\n",
       "5                  profe demora entregar notas    Negativo\n",
       "6                  gusto competir mejor modelo    Positivo\n",
       "7                               examenes largo    Negativo\n",
       "8                           aprendi gradientes    Positivo\n",
       "9                                  aprendi nlp    Positivo\n",
       "10                    aprendi redes neuronales    Positivo\n",
       "11                     falto aprender ma spark    Negativo\n",
       "12                         office hour sabados    Negativo\n",
       "13                              aprendi python    Positivo\n",
       "14                                 aprendi pca    Positivo\n",
       "15                             aprendi cluster    Positivo\n",
       "16                            tareas practicas    Positivo\n",
       "17                  aprendi q derivadas utiles    Positivo\n",
       "18                       panda com excel gusto    Positivo\n",
       "19  confio grabaciones distraigo parte teorica    Negativo"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datosFinalClear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65b4153a-e1e7-4e64-b40c-85c833dc9216",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabras más importantes: ['utilizar' 'tareas' 'panda' 'gusto' 'excel' 'redes' 'com' 'aprendi'\n",
      " 'neuronales' 'practicas']\n"
     ]
    }
   ],
   "source": [
    "# Continuación con la implementación del algoritmo de gradiente descendente\n",
    "X_train, X_test, y_train, y_test = train_test_split(datosFinalClear['Texto'], datosFinal['Sentimiento'], test_size=0.2, random_state=42)\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "model = SGDClassifier()\n",
    "model.fit(X_train_vec, y_train)\n",
    "\n",
    "# Obtener las palabras más importantes\n",
    "feature_names = np.array(vectorizer.get_feature_names_out())\n",
    "coeficients = model.coef_[0]\n",
    "important_words = feature_names[np.argsort(coeficients)[-10:]]  \n",
    "print(\"Palabras más importantes:\", important_words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
